---
layout:     post
title:      读书笔记： 从应用到创新
subtitle:   Reading Notes
date:       2020-04-25
author:     MZ
header-img: img/post-bg-Reading-cyydcx.jpg
catalog: true
tags:
    - Reading Notes
---

# 从应用到创新阅读笔记

> Vivo基带实习入职读物

## 第一章 移动通信发展史及关键技术

### 1.1 无线电通信发展史

略

### 1.2移动通信网

![JaUVtH.png](https://s1.ax1x.com/2020/04/23/JaUVtH.png)

#### 1.2.1 **交换子系统**（SSS）

交换子系统负责整个通信系统的运行、管理，它可以在任意两个用户（或者信道）之间建立或释放一条通信链路。其中包含：

**1. 移动交换中心（MSC）**

MSC是一个由计算器控制的全自动移动系统，与基站通过光纤通信，一个MSC可以管理数十个基站，并组成局域网。每个MSC都有一个访问位置寄存器（VLR），以及归属位置寄存器（HLR）、设备号识别寄存器（EIR）、鉴权中心（AUC）。

**2. 访问位置寄存器（VLR）**

访问位置寄存器（VLR）是一个存储来访用户（又称为“拜访客户”）信息的数据库。手机的不断移动导致其位置信息不断变化，这种变化的位置信息就在VLR中进行登记。所以是一个动态寄存器。

**3. 归属位置寄存器（HLR）**

HLR用于存储本地用户位置信息。当用户购买手机后第一次使用SIM卡加入移动网络，必须通过MSC在当地的HLR中登记注册，把相关信息存储在HLR中。当呼叫一个不知道处于哪一地区的手机时，均可由HLR获得该手机原始位置参数，获得它的当前状态，从而建立起通信链路。所以是一个静态寄存器。

**4. 鉴权中心（AUC）**

鉴权中心（AUC）用于识别用户身份，只允许授权用户接入网络并获得服务。AUC给每个用户一个认证参数，供VLR进行认证。

**5. 设备识别号寄存器（EIR）**

每台手机都有一个国际移动设备识码（IMEI），设备识别号寄存器（EIR）通过IMEI码监视和鉴别移动设备，拒绝非法移动台登网。

显然，我国几大运营商没有利用IMEI码对手机进行鉴别。否则，也不会有前几年山寨机的大泛滥了（IMEI码可是要花钱买的噢）。

#### 1.2.2 基站子系统（BSS）

基站，又称基地台，它是一个能够接收和发射无线电信号的固定电台，负责与手机之间进行通信联络。基站子系统（BSS）包括基站收发器（BTS）和基站控制器（BSC）。

**1. 基站收发器（BTS）**

它由若干部收发信机组成，每部收发信机占用一对双工收发信道，如业务（话音）信道（TCH）及控制信道。

基站拥有的收发信机数量相当于有线电话的“门”数，基站的收发信机越多，用户“抢线”就越容易。一般，一个基站收发器大约有数十部收发信机。

**2. 基站控制器（BSC）**

基站控制器负责基站收发信机的运营、呼叫管理、信道分配、呼叫持续等功能。一个BSC可以控制管理多达256个基站收发器。

一个基站控制器（BSC）和数十个基站收发器（BTS）组成一个基站，每个基站为一定覆盖范围内的手机提供通信网络服务，构成一个蜂窝小区。

#### 1.2.3 操作维护子系统（OMS）

操作维护子系统（OMS）又称操作维护中心（OMC），负责对全网进行监控和操作，如系统报警、故障诊断、话务量统计、资料传递等。

OMS一般处于移动交换中心（MSC），也可以看作交换子系统的一部分。

#### 1.2.4 移动电话机（MS）

移动电话机（MS）在早期是以车载台、便携台的形式出现的，现在则为大众化的移动电话机——手机所取代，车载台仍有少量生产，主要应用于通信或军事部门。

手机，主要由射频部分（一般称为Radio Frequency，RF）、逻辑控制与音频处理（一般称为Base Band，BB）两大部分组成。针对不同的通信网络系统，手机的电路结构有所不同，但基本架构都是RF+BB，且电路部分的基本原理也区别不大。而真正有本质区别的部分（如BB的多址接入、RF的线性/非线性功放），对于普通用户来说，都是完全屏蔽的，也不为用户所感知。

### 1.3 多址接入

我们有时候会听到某某人说，我的手机是3G的，你的是2G的；或者有人说，我的手机是CDMA的，你的是GSM的。那么，CDMA、GSM到底是什么意思？

其实，CDMA的全名为Code Division Multiple Access，指的是一种多址接入技术；GSM的全称为Global System for Mobile Communications，即全球移动通信系统。从字面上看，CDMA显然是指一种技术手段，而GSM纯粹就是个名字，两者真的是风马牛不相及。

但是，很多时候，我们都把这两个名词放在一起讲，好像它们之间存在对应关系似的。

事实上，我们在说GSM的时候，更多的是在强调GSM所采用的TDMA多址接入技术（确切地讲，GSM是TDMA+FDMA的结合）。所以，让我们首先看看什么叫多址接入。说白了，多址接入的唯一目的就是在不增加其他投入的情况下，尽可能地增加用户数量，使众多用户可以共享通信信道，并确保他们之间尽可能不会相互影响。显然，这也是电信运营商所期望的事情。

目前，移动通信采用的多址接入方式有FDMA（Frequency Division Multiple Access，频分多址）、TDMA（Time Division Multiple Access，时分多址）、CDMA（Code Division Multiple Access，码分多址）三种基本类型。实际中，常常是三种基本方式的组合，如GSM系统采用TDMA+FDMA组合的方式。

以下，我们对这几种多址接入技术进行简单介绍。

#### 1.3.1  频分多址（FDMA）

不同的用户占用不同的频点（实际由系统分配），就可以实现互不干扰。早期模拟手机采用这种方式接入。

但是这种接入方式的用户容量极其有限。类似无线电台，为了保证不同电台之间不会相互干扰，电台与电台之间的最小频率间隔必须大于电台的带宽。对于FDMA的通信用户来说，也存在同样的问题。

#### 1.3.2 时分多址（TDMA）

假定现在有两个人在同时通信，并且他们占据同一个频点。我们可以把时间分片，划定一个个短小的时隙片段，并设定第一个人在时间片1（称为Slotl）进行通信，而第二个人在时间片2（称为Slot2）进行通信，并让Slotl与Slot2反复切换。只要时间片足够短，同时通信的两个人就不会感觉到时间片存在切换现象，就好像自己独占了通信通道一样。（类似单核多任务）

学过信号系统课程的读者应该还有印象，TDMA技术的理论依据其实就是著名的香农采样定理，也称奈奎斯特采样定理，即一个频带受限信号可以用采样频率为两倍带宽的抽样值唯一地确定。因此，第一个用户仅仅在第一个抽样瞬间占用信道，第二个用户仅仅在第二个抽样瞬间占用信道，然后是第三个用户、第四个用户，依次下去。于是，原本采用FDMA技术的移动通信小区，在采用FDMA+TDMA技术后，可以容纳的同时通信用户数量迅速增加。

#### 1.3.3 码分多址（CDMA）

CDMA（码分多址）则是一种更加高级的接入方式，并成为各个3G标准的核心技术。

在CDMA系统中，不同用户传输信息所用的信号不是靠频率不同（如FDMA）来区分，也不是靠时隙不同（如TDMA）来区分，而是靠不同的编码序列来区分。如果从频率域和时间域同时观察，多个CDMA用户的信号是互相重叠的。

一直以来，有个关于FDMA、TDMA、CDMA的形象比喻。联合国开大会时，男人的声调低沉，女人的声调尖锐，就好比是FDMA，通过频率来区分男女；美国说话的时候，英国不说话，英国说话的时候，澳大利亚不说话，就好比是TDMA，大家占用不同的时隙通信；美国人说英语，中国人说汉语，法国人说法语，就好比是CDMA，大家用不同的语言同时交流而互不影响。

这个比喻很形象，对FDMA和TDMA的解释也很到位，唯独对CDMA码分多址技术解释不足。CDMA的理论依据是信号的正交分解，利用正交坐标轴/正交编码，我/系统就可以轻松分辨出各兄弟/各用户的运动轨迹/通信内容。

从上述比喻我们还可以推断出CDMA的一些特点。

（1）CDMA系统容量大

GSM系统在FDMA基础上采用TDMA技术后，可以成倍地扩充系统容量。但无论如何，系统容量最终还是要受到频带宽度和时隙长度的限制。而CDMA技术就很方便了，原先有N个用户在通信，现在又增加了一个，好吧，那就把N维正交空间扩展为N+1维正交空间，相当于再增加一个正交编码组不就搞定了！这便是CDMA多址接入技术所谓的软容量概念。

确切地讲，CDMA软容量分为两种情况。一种是适当降低业务信道（一种逻辑信道，可参考1.4.2节的信道编码，有关于物理信道、逻辑信道的简单解释）的误码性能，从而在短时间内提供稍多一些的可用信道数。另一种是当业务信道也接近饱和以后，则占用寻呼信道，极端情况下，甚至占用同步信道，把寻呼信道和同步信道统统作为临时的业务信道使用，从而扩充系统容量（由于CDMA系统中各个逻辑信道之间也是相互正交的，所以该方法的确有点增加/抢占正交编码的意味）。

如果我们把眼光扩展到多小区的CDMA系统，则可以通过各小区负荷量的动态调整来扩充系统总容量。重负荷小区降低本小区的导频信号功率，等效为缩小其小区覆盖范围；而轻负载小区则可以提高导频信号功率，等效为扩大其覆盖范围。从整个系统上看，轻/重负载小区实现了动态覆盖，自然可以增加系统的总容量。所以，该方法也被称为“小区呼吸”功能。不过，在通常情况下，CDMA系统软容量指的是前述两种情况，与小区呼吸无关。

而作为FDMA与TDMA系统，如果频带和时隙被全部占用，那么即便再增加一个用户，也是不可能的。当然了，CDMA系统容量也不可能无限增加。毕竟，增加用户会产生多址干扰，当干扰到达一定阶段时，就会对系统正常工作产生严重影响。

（2）CDMA可实现软切换

无论FDMA、TDMA还是CDMA系统，当用户在通话状态下从一个小区移动到另一个小区后，为了保证通话连续，都必须进行小区切换。在CDMA系统中，有硬切换（Hard Handoff）和软切换（Soft Handoff）两种方式。

硬切换是指移动台MS（即手机）在不同频道之间的切换，比如手机在同一个MSC的不同频道之间或者不同MSC的不同频道之间进行切换。这些切换需要手机变更收发频率，即先切断原来的收发频率，再搜索、使用新的频道。硬切换会造成通话的短暂中断，当切换时间较长时（如大于200ms），将会影响用户通话。第一代模拟通信系统（采用FDMA方式）与第二代GSM数字通信系统（采用FDMA+TDMA混合方式）均采用硬切换，所以只要移动台进行小区切换，就一定存在“掉话”风险。

但CDMA系统还有一种软切换方式。当小区中的所有用户均使用同一组收发频率或者不同基站的扇区均使用同一组收发频率时，若移动用户开始越区切换，则无须进行频率切换，只要对PN码（即前文所说的正交码）的相位做相应调整即可。不仅如此，CDMA系统的手机采用Rake接收机（一种抗多径衰落的算法），可以使手机与新基站建立业务链路的同时，并不中断与原来服务基站的联系，直到手机接收到的原基站信号低于某个门限时，才完全切断与原基站的联系。换言之，软切换是先接通后切换的技术。于是，采用软切换方式的手机就不存在“掉话”风险。

（3）CDMA无TDD Noise问题

所谓TDD，即时分双工Time Division Duplex的缩写。GSM系统采用TDMA技术，宏观上，用户似乎一直占用着信道；但微观上，用户仅仅是在一个个时隙中进行数据传输，其余大部分时间都保持空闲。这样做的好处一方面是增加了系统容量，另一方面可以有效降低手机RF发射机的平均功率（毕竟，手机不同于基站，它是靠电池供电的）。但同时带来一个副作用，就是令我们手机硬件研发人无比头疼的TDDNoise问题（有时也被称为TDMA Noise）。

对于手机来说，RFPA属于大功率器件，在某个固定的Slot中发射数据，而其余Slot保持空闲，会产生一连串的Burst，从而造成系统电源（特别是电池电压bat）在对应的Slot片段中出现剧烈波动，进而导致整个系统电源的波动，而且发射功率越大，影响也越大，并最终影响到其他敏感信号线。若干扰到I/Q信号，则导致各种RF指标不合格；若干扰到Audio信号，则产生所谓的TDDNoise，使本机听筒产生“吱吱吱”的噪声或者影响上行链路导致对方听到“吱吱吱”的噪声。该现象为GSM系统所固有，只能优化，不能消除，非常考验手机研发人员的设计水平。但CDMA技术不存在Burst，自然也就没有TDD Noise之虞了。关于这个问题，我们还将在提高篇与案例分析篇中进行深入探讨。

### 1.4 编码与数字调制

语音通话还是手机最核心、最本质的需求。所以，我们有必要了解一下手机的语音编码、信道编码与数字调制技术。首先，我们看看上行（发送）语音方向的处理流程，如图1-4-1所示。

![Jd0Z7V.png](https://s1.ax1x.com/2020/04/23/Jd0Z7V.png)

原始模拟语音信号经Microphone拾取、放大、采样、量化后进行语音编码，然后经信道编码，最后经数字调制，再把信息传送RF（Radio Frequency）模块发射出去。至于下行方向的语音处理流程，则相当于上行方向的逆过程。

#### 1.4.1 语音编码

话筒，俗称麦克风（Microphone），是一种声/电转换装置，它将说话人的连续语音信号转变为相应的连续电信号，经模拟放大器放大后，送至A/D芯片进行采样（连续时间变成离散时间）与量化（连续信号变成离散信号），最后再经编码器进行语音编码。在通信系统中，语音相当于信源，所以语音编码也被称为“信源编码”。

**1. 统计编码**

最简单的编码方式就是直接对量化数据采用原码的方式，实际上就是不编码。但是，如果不编码则平均码长较长。如果进行编码，并规定出现概率高的分配短码字，出现概率低的分配长码字，会在传输同样的信息时实现数据压缩，提高系统容量。

**2. 参量编码**

前面所说的数据采样与量化可以看成一种波形编码，即对语音信号波形本身进行编码，信息压缩率有限。而参量编码则是一种信源编码，它是以语音信号产生的数字模型为基础，提取若干特征参量（也称特征值），然后对这些特征参量进行编码的方法。

研究发现，语音信号的产生也可以通过一种数学模型实现，即用白噪激励语音生成器获得（可参见相关语音信号处理教材，笔者读研究生时的导师就是干这个专业的）。直观上，用数学模型产生的语音信号肯定不及真人发声的语音信号真实，事实上也是如此。但数学模型最大的好处就是可以获得语音信号的特征值，其数据量远远小于真实的语音信号。于是，对这些特征值进行编码传输，然后在接收端利用这些特征值，同样可以实现语音信号的重构，这便是所谓的参量编码。

对比波形编码方式，参量编码的压缩率更高，也就是传输码率更低，通信系统的负担也更低，缺点就是解码后的信号失真较为严重。

**3. 混合编码**

GSM系统采用所谓的规则脉冲激励长期预测编码（PRE-LTP），既含有基于语音特征的参量编码，又包括部分波形编码信息，而且采用预测编码，可以更进一步地压缩码率。至于预测编码可以压缩码率的理论，则是基于香农的信息论。预测越准确，则误差越小，误差越小则表明误差本身的概率密度分布也就越集中，即误差函数自身的熵值也越小。嫡值越小，则表明平均码长越短，码率也就降低了。通常，几乎所有关于信息论的教材对此都有详细讨论，笔者就不再赘述了。

#### 1.4.2 信道编码

我们知道，移动通信采用无线电传输信息，固定电话采用有线电缆传输信息。但无论有线通信还是无线通信，信息总是要通过某种通道进行传输的。对于固定电话，我们可以认为电缆就是其信息传输通道；而对于无线通信，我们则把高频无线电载波所处的具有一定宽度的频带看成信息传输通道。

FDMA移动通信系统与FM广播电台情况类似，不同的手机占据不同的频带（由系统随机分配），也就是说，各个手机在各自被分配的通道上传输信息，互不影响。

对于TDMA，在某个GSM（FDMA+TDMA）系统的小区来说其所能的总通道数就是总频点数乘以每个频点所能提供的时隙。

对于CDMA码分多址移动通信系统而言，不同的用户使用不同的正交编码，那么每一个独特的正交编码就相当于一个信息传输通道。

可见，FDMA系统的信息传输通道可用频带的概念代替，GSM系统中的通道则从频带衍生到时隙，而CDMA则进一步演化到正交编码的概念。为了剥离这些通道的具体物理意义，我们将其统称为信道。相应地，FDMA称为频分信道，TDMA称为时分信道，CDMA则称为码分信道。不过，需要着重指出一点，我们这里所说的信道均是指物理信道，与逻信道可不是一个概念（逻辑信道都是承载在物理信道上的，只是由于传送的信息在逻辑上分属不同类型，才被称为逻辑信道）。打个比方，CPU与Memory之间的地址总线是行地址/列地址复用的，物理上是同一组地址总线，只是在传输不同逻辑信息时，才称之为行地址或列地址。类似的概念，还有I$^2$C接口、NAND等器件的数据/地址复用同一套总线。

下面，我们解释一下信道编码的意思。我们都知道，信号在信道中传输，一方面信道传输特性不理想，会导致信号发生失真与畸变；另一方面，信道中的各种干扰、噪声又会影响信号的传输。最终结果，都是导致信号在经过信道传输后出现差错。于是，人们就设计出了信道编码，用于改善数字信息在传输过程中由于各种噪声、干扰所造成的误差，提高系统的可靠性。

事实上，信道编码并不是对信道本身进行编码。信道编码，其实是对语音编码后的数字信号序列按照一定规则，插入一些非信源信息的数字序列，以构成一组码字，然后经调制器转换为适合信道传输的信号。经信道传输后，接收端再采取相反的措施，经信道解码去除源端插入的数字序列，然后再经语音解码还原出原始语音。也就是说，信道编码其实是为了纠正信道传输的错误，有意在信源中插入冗余信息，然后接收端可以根据这些冗余信息正确地还原出信源信息。当然了，信道编码的纠错能力也是有限制的，它与具体的编码方法有关。

在完成信道编码后，还要进行交织等处理，才会进入数字调制过程。在移动通信系统中，数据是以数据帧的形式，一个个分别发送/接收的，而交织其实就是按照某个规则打乱原先数据帧的排列顺序。这样做，看似无理，实则巧妙。移动通信的传输信道属于变参信道，它会造成一连串相邻码元的突发错误。但是，将数据帧打乱传输后，发生错误的码元，在时间排序上相距很远。这样，利用信道编码的纠错能力，就能根据错误码元的相邻码元信息，而把错误码元给检测出来并纠正。但是，如果不进行交织，一旦一连串顺序码元同时发生错误，信道编码也就无能为力了。

#### 1.4.3 数字调制

所谓调制，即用发送信号（也称调制信号）调变载波的某个参数，使载波跟随发送信号规律变化。于是，接收端对接收信号进行反向处理，就可以还原出发送端的发送信号。另外，我们知道调制信号可以是模拟信号，也可以是数字信号。同样，载波信号可以是连续波（基本都是正弦波），也可以是脉冲序列。两两组合，就有模拟/数字连续波调制和模拟/数字脉冲调制共四种方式。

对于手机来说，载波信号都是连续波，所以只可能是连续波调制。第一代手机的调制信号为模拟信号，采用模拟连续波调制方式（简称模拟调制），这便是模拟手机名称的由来；而从第二代手机开始，调制信号均为数字信号，采用数字连续波调制方式（简称数字调制），从而诞生数字手机一词。可见，所谓模拟/数字手机，指的是调制信号的类型，与载波无关。

相比于传统的模拟调制技术，数字调制具有容量大、质量好、安全性高等特点，但占用带宽比模拟通信要多得多。这是显然的事，天下没有免费的午餐嘛。

数字调制的方法各式各样，针对不同的应用场景往往有不同的方案，甚至一个系统可同时支持多种调制方式。比如，欧洲GSM系统采用的高斯滤波最小频移键控技术，即GMSK（Gaussian Filter MSK）调制；美国D-AMPS系统与日本PDC系统均采$4/\pi$DQPSK调制；DVB（数字视频广播）与WLAN（无线局域网）均采用OFDM调制；蓝牙采用GFSK调制。

随着技术的发展，各系统所支持的调制方式也有所增加，如蓝牙在2.0规范中增加了元$4/\pi$DQPSK与8PSK调制方式。

最后，给出一个完整的数字手机的通信系统框图（仅仅是手机通信功能的组成框图，并非手机硬件框图），如图1-4-2所示。

![Jwle1K.png](https://s1.ax1x.com/2020/04/23/Jwle1K.png)

### 1.5 我国移动通信发展史

略

## 第二章 手机电路系统组成

### 2.1 手机的基本架构

我们不妨把手机看成一台具备无线电发射与接收功能的微型电脑，如图

![JwYRu6.png](https://s1.ax1x.com/2020/04/23/JwYRu6.png)

做硬件开发，我们可以把手机分为初级系统、中级系统和高级系统三类。

**1. 初级系统**

所谓初级系统，就是为实现手机基本功能所必需的最小系统，比如，由CPU+Memory+LCD+RF所构成的最简单手机。

**2. 中级系统**

中级系统则是在初级系统基础上增加了多种功能，如Camera、Bluetooth、FM、GPS等。如果一部手机具备了Camera、Bluetooth，我们称之为中级系统；如果在此基础上增加了FM，我们仍然称之为中级系统；如果继续增加功能，比如Wi-Fi、E-Compass、GPS等，我们还是称之为中级系统。

道理很简单，无论增加多少功能模块，对于系统来说，都是相当于挂在CPU上的外设，都是由同一个CPU统一维护管理的。只是系统的复杂性有所增加，但设计思路并无区别。

**3. 高级系统**

假定有一个GSM制式的最小系统手机，还有一个CDMA制式的最小系统手机，现在要求把这两个最小系统做在同一部手机里面，你觉得难度如何？

看上去似乎不难，但是你想想，它们是不是要共享同一个LCD、Microphone等设备（用操作系统术语来说，就是多个任务要互斥访问共享资源）？它们之间需不需要互相通信？它们之间到底谁做主控、谁做从控？如果一个系统出现故障，另一个系统还能不能工作？

所以，即便把两个简单的最小系统融合在同一部手机里面，也远比设计一个功能复杂的单系统机器要复杂得多！

看到这，有人可能会说，既支持CDMA又支持GSM，这不就是双模机吗？不错，这是双模机，但双模机有两种类型。一种就是前面说到的，分别由两个系统组合在一起实现的双模机，其中每个系统都有自身的一套BB和RF；另一种则是1BB+2RF构成的双模机。所谓1BB是指只有一套BB电路，而2RF则是指有两套RF电路。比如高通的MSM7227平台，由于UMTS是GSM的升级，所以GSM与UMTS的所有协议均可以在同一套BB电路中运行，但GSM与UMTS的频段不一样，RF调制方式也不一样，所以必须要设计两套RF电路。从这个意义上看，两套RF与一套RF并没有本质区别，可以把它们看成外挂在同一个Base Band上的两套外设而已，这种双模机也更接近于中级系统。

从另一个角度看，双系统机器支持双待双通功能，即当一个系统处于通话状态时，另一个系统也可以拨打/收听电话，只是因为两个系统共用同一套电声器件，所以在实际上不可能实现双系统的同时通话。不过，一个系统通话，另一个系统下载文件，这倒是允许的。对于单系统的双模机，实际上是分时工作原理，通过操作系统的调度使得系统在两个模式下轮流工作。所以，单系统双模机实际上是双待单通。

但是，最后要说明一点，这里划分低、中、高，并不表明高级系统就一定比中级系统难设计，中级系统就一定比低级系统难设计，我们仅仅是从硬件架构的复杂性来划分低、中、高。事实上，往往低级系统更加考验设计者的功力，因为低级系统的售价摆在那里，在满足一定性能指标的前提下尽可能压缩成本，谈何容易？该用6层板的用4层板，该用1阶板的用通孔板（关于PCB的基础知识可参见后文），该用TVS的省掉不用，这便是很多Design House最后关门的原因所在，只要出一丁点批次性故障，卖一百台的利润都不够返修一台的费用。

说到这儿，笔者不由地想起汽车中的Crown与Reiz，两部车采用同样地平台，价格却差1/3~1/2，其中的门道，不说你也应该懂了吧！

### 2.2 手机基本组件

#### 2.2.1 CPU与PMU

CPU即中央处理器，在PC领域，有Intel系列、AMD系列等，但在手机领域中，则有高通系列、MTK系列、TI系列、ADI系列等众多生产厂家。目前在国内，最为著名、应用也最为广泛的当属美国高通系列和中国台湾MTK系列。

不同于PC中的通用CPU，手机的CPU除了支持常规的控制与传输功能外（如I$^2$C、Interupt等），还要参与很多与信号处理相关的任务，如语音编译码、基带信号调制解调等。顺便说一句，控制功能一般在CPU 中Application Procesor模块中处理，而与无线通信相关的功能一般在Modem模块中处理。所以一般情况下，我们并不把手机中的CPU称为CPU，而是直接称其为高通某某平台、MTK某某平台。如高通MSM7X27平台、MTK657X平台等，这里的MSM7X27与MTK657X就是指所用CPU的型号。至于双核、四核平台，则指物理上是一颗CPU，但在其内部有多个内核可以并行工作。若操作系统可以很好地配合多核CPU，把一些大型任务/进程分配到多个内核上同时运行，那就可以极大地提高程序运行效率。图2-2-1为MTK6589四核CPU的组成框图（指APMCU由四颗ARMCortexA7内核组成）。

![Jw6dzT.png](https://s1.ax1x.com/2020/04/23/Jw6dzT.png)

PMU是Power Management Unit的缩写，即电源管理芯片（相当于PC的电源箱），由电池输入电能（相当于PC电源箱的220V交流输入），经PMU处理后，提供系统所需的各路电源（相当于PC电源箱输出的各路电源）。

在大多数中高端平台中，CPU与PMU是两个独立的芯片，如高通的MSM7X27+PMU8029；但在一些低端平台中，两个芯片经常整合在一起，如高通的QSC62X0平台。图2-2-2所示PMU为高通的PM8029，仔细分析该图不难发现，PM8029不仅会提供各路电路给系统供电⑥，还支持充电管理②、音频输入/输出④、时钟管理③、SIM卡管理及若干GPIO⑤等各种功能。不同的PMU芯片会有不同的功能，有些可能不支持音频输入/输出，有些可能不支持SIM卡管理。但无论如何，PMU最本质的需求是提供并管理整个系统的电源，至于其他功能则不是必需的。

观察图2-1-2与图2-2-1不难发现，这两个型号的CPU在物理上是一个芯片，只是在芯片内部被划分了不同的模块，分别完成控制、通信、调制/解调等功能。但在有些平台中，比如ADI系列，这些功能本身是由两个芯片分别实现的。相应地，完成控制、通信等功能的称为DBB（Digital Baseband，数字基带，比如AD6525），而完成调制/解调等功能的称为ABB（Analog Baseband，模拟基带，比如AD6521）。另外，还有些平台会把PMU电源管理部分集成在ABB中。

但不管DBB、ABB等器件在物理上是集成的还是分离的，从逻辑上看，它们都可以等效为CPU+PMU的架构。

![JwRE1P.png](https://s1.ax1x.com/2020/04/23/JwRE1P.png)

#### 2.2.2 Memory

同所有的电子线路一样，手机中的Memory也分为ROM与RAM两大类（说明一下，通常意义上的Memory均指RAM，但本书不予区分）。目前，手机中的ROM基本全部是Flash型ROM，这是一种可读亦可写的非易失性存储器；而RAM则基本上由SDRAM或者DDR SDRAM所组成（也有少量平台使用PSRAM）。

**1. Flash**

在手机中，Flash又有两种基本类型，分别是NOR与NAND。1988年，英特尔公司首先开发出NOR Flash技术，彻底改变了原先由EPROM和E2PROM一统天下的局面。紧接着,1989年，东芝公司发表了NANDFlash结构，强调降低每比特的成本，更高的性能，并且像磁盘一样可以通过接口轻松升级。

NOR的特点是芯片内执行（Execute In Place，XIP），这样应用程序可以直接在NOR Flash内运行，不必再把代码读到系统RAM中。除此以外，NOR的传输效率很高，在1~4MB的小容量时具有很高的成本效益，但是很低的写入和擦除速度大大影响了它的性能。所以，过去在80C51等小型单片机系统中多使用NOR Flash。
NAND结构能提供极高的单元密度，可以达到高存储密度，并且写入和擦除的速度也很快。

但是，NAND需要特殊的系统接口，管理难度也远比NOR要大得多。在批量生产中，NAND Flash的单元尺寸几乎是NOR器件的一半，由于生产过程更为简单，NAND结构可以在给定的模具尺寸内提供更高的容量，也就相应地降低了价格。所以，NANDFlash更适合数据存储，在Compact Flash、Secure Digital Card和eMMC存储卡市场上所占份额最大。

但是，从硬件工程师的角度来看，NOR与NAND的区别不在于容量，读写速度等区别而是两者与CPU的接口有很大的不同，如下图所示。

![JBeBQg.png](https://s1.ax1x.com/2020/04/24/JBeBQg.png)

![JBeWWT.png](https://s1.ax1x.com/2020/04/24/JBeWWT.png)

仔细对比NOR与NAND的接口不难发现，NORFlash采用SRAM接口，通过地址线A0-A22来寻址，通过数据线DQ0-DQ15（复用地址线A0-A15）来读写数据，与访问普通的SRAM并无二致，所以可以很容易地存取其内部的每一个字节。

而NAND的接口器件使用复杂的I/O口来存取数据，地址、命令、数据复用I/O1-I/O16总线（有的芯片为I/O1~I/O8），通过ALE、CLE等控制信号区分总线信息。NAND读和写操作采用512字节的Page（也有采用2KB、4KB等各种大小的Page），这一点比较像硬盘的读写管理操作，很自然地，基于NAND的存储器就可以取代硬盘或其他块设备。

**2. SDRAM**

SDRAM的全称为Synchronous Dynamic RAM，即同步动态随机存储器。除了容量、封装等非电气特性外，手机中的SDRAM与PC中的SDRAM在电气特性上并无本质区别，而且越来越多的手机开始采用支持双边沿传输的DDRSDRAM。

不过，手机中一般看不见单独的SDRAM或DDR SDRAM，因为现在的芯片封装技术早已把Flash 与SDRAM集成在一颗芯片内，即MCP（Multi-Chip Package Memory，多芯片封装存储器）。

于是，MCP就有NOR+SRAM和NAND+SDRAM两类。图2-2-4所示的NOR Flash其实就是一个NOR+SRAM型MCP。特别指出，不同厂家对该类型MCP的SRAM有不同的称呼，如Intel称为PSRAM，而Samsung则称为UtRAM。事实上，该类型MCP内部的SRAM采用的是类似于SDRAM的颗粒架构，只是为了方便与NORFlash共享同一套接口，才把SDRAM也设计成了SRAM的接口，故而称为Pseudo SRAM。因此严格说来，该类型MCP应该属于NOR+SDRAM架构。由此我们看出，PSRAM集成了SRAM接口简单、节省空间，以及DRAM省电、容量大的特点，非常适合手机等便携式电子产品应用领域。

某NAND+SDRAM型MCP接口如图2-2-5所示。

![JBwLqA.png](https://s1.ax1x.com/2020/04/24/JBwLqA.png)

由于NAND接口十分复杂，导致各厂家、各工艺的NAND芯片之间的兼容性不好，使得手机设计厂家在更换供货商甚至同一供货商不同工艺生产的NAND芯片时颇为头疼。于是，eMMC技术应运而生。它把NAND芯片的控制器及相关协议集成在MCP芯片内部，对外只提供1/4/8bit数据线和很少的几根CLK、RST、CMD等控制线，与SD卡、T-Flash卡的接口极为类似。复杂的协议控制交由MCP芯片自身负责，手机设计厂家仅需要关注产品开发的其他部分，从而大大简化了手机厂家的工作量。

三星某型号eMMC的内部组成框图见图2-2-6所示。

![JBrnRf.png](https://s1.ax1x.com/2020/04/24/JBrnRf.png)

#### 2.2.3 Transceiver

Transceiver是Transmitter与Receiver的合称，即收发信机，简称收发机。

手机的本质是无线电通信电台，必然要有发信机（发射机）和收信机（接收机）两个模组。在模拟通信和早期的数字手机中，Transceiver真的是由发信机和收信机两个分立的模组构成。但随着集成电路工艺技术的进步，如今的手机，基本上都已经把Transmiter与Receiver集成在同一个芯片中了，故称之为Transceiver（一些单芯片平台，如高通QSC6240/6270，Transceiver 与Base Band都集成在同一颗芯片中）。

Transceiver中的发信机把CPU送过来的基带信号（如GSM手机的GMSK信号，CDMA手机的QPSK信号）调制在高频载波上，然后传送给RFPA进行功率放大；其收信机则把高频LNA（Low Noise Amplifier，低噪放）传送过来的高频信号解调成基带信号，然后再交给CPU进行下一步处理。就电路功能分析，Transceiver的目的很单一，仅仅是完成将基带信号调制在高频载波上或者将高频信号解调成基带信号，其实现的功能远没有基带电路部分的CPU复杂。但实际上，Transceiver也是一个相当复杂的系统，手机通信质量的好坏与它有密切关系的。

一个四频段GSM Transceiver（AD6548）的内部框图如图2-2-7所示。

![JBrWQO.png](https://s1.ax1x.com/2020/04/24/JBrWQO.png)

在AD6548内部，主要为三个模块，一个是TXChannel（采用的偏移锁相环架构），一个是RXChannel（采用直接下变频架构），另一个是Local OSC（采用锁相环架构）。

对于LocalOSC（本振），我们知道，高频信号的混频、调制其实都是一种频谱搬移过程，显然离不开本振。这个很好理解，笔者就不解释了。对于Receiver，高频信号与同频率的本振信号混频后，可以直接得到基带I/O信号。

#### 2.2.4 RF PA

RF PA即高频功率放大器，用来放大Transceiver输出的高频已调信号。学过低频模拟电路课程的读者知道，根据功率管的导通状态，功放分为A类（亦称甲类）功放、B类（乙类）功放、AB类（甲乙类）功放和C类（丙类）功放；根据功率管的等效电路，功放分为D类（丁类）功放、E类（戊类）、F类、G类、H类等各类型。
进一步，我们知道，功放本身并不提供能量，它只是把电源提供的直流能量转化为所需要的交流能量，并且功放本身还需要消耗一定的能量。所以，考察一个功放性能的好坏，主要从线性度和效率两方面着手。
A类功放线性度最好，理想情况下，输出波形无失真，但效率最低。采用变压器耦合或扼流圈耦合的A类功放，最高效率为50%，直接耦合的A类功放（如各种小信号放大器），其最高效率只有25%。
B类功放，由于“死区”的存在，导致输出波形在正、负半周转换时出现交越失真，但最大效率接近78.5%（n/4）。AB类功放采用微导通方式，给功率管提供一个微小的静态偏置，可有效克服交越失真现象，但最大效率要略有下降。
C类功放内部功率管的静态偏置点位于负半轴，只能对正半周信号进行放大，负半周信号截止，所以波形完全失真，但效率最高。在导通角为60°~70°时，最大效率可超过80%，可参考提高篇的图9-4-9。不过，由于此时功率管输出信号只有半个周期，所以功率管的集电极就不能接普通的电阻负载，而只能使用LC选频回路了。根据高等数学中的傅里叶级数（FourierSeries）原理，一个周期信号可以用直流、基波及其各次谐波的正/余弦三角函数展开。所以，利用LC选频回路取出所需要的频率分量，就可以获得不失真的高频信号。
至于D、E类等功放，与A、B、C类功放最大的区别在于，A、B、C类功放的输入/输出信号均为正弦波（C类功放的输出电流近似为半周期余弦脉冲，但由于选频回路的作用，其电压波形基本为完整的正弦波），而D、E类功放的输入信号为正弦波、输出信号则为方波。此时，D、E类功放的功率管被等效为一个开关器件，而不是放大元件。但在手机电路中，只有音频部分会用到D类功放驱动Speaker（主要为提高功放效率），射频部分尚未应用D、E类开关功放，我们就不再多做介绍了。

同低频模拟电路类似，在高频电路中，也有A、B、C、D等各种类型的功放。具体到手机电路中，由于不同制式的手机采用不同的基带调制方法，使得不同制式的手机，其高频功率放大器的类型也各不相同。

比如GSM手机，采用GMSK调制（Gaussian Filter MSK，高斯滤波最小频移键控），属于非线性调制方式，是一种恒包络信号（即高频载波的幅度恒定）。所以，GSM手机的高频已调信号，其幅度不带信息，而频率携带信息（数学上，频率表示为瞬时相位对时间的导数，故可等效为相位携带信息）。

因此，GSM手机的RFPA选用C类功放，从而实现高效率。

#### 2.2.5 天线电路

我们知道，天线作为一种无源器件，其发射/接收是互易的，即天线的辐射特性与接收特性完全相同。所以，一根天线既可以作为发射天线使用，也可以作为接收天线使用。当然，如果通信机的发射/接收频段相距很远，则由于一根天线带宽无法同时覆盖发射/接收时，人们才会设计单独的发射天线和接收天线。

#### 2.2.6 LCD

LCD，全称为Liquid Crystal Display，即液态晶体显示，简称液晶显示或更直接地称为液晶。

下面，我们对LCD的分辨率、可视角、色彩深度以及借口模式等重要参数加以简要介绍。

**1. 分辨率**

分辨率指的是LCD屏幕的行、列像素，常以点阵（矩阵）形式表示。由于VGA（Video Graphic Array）最早是由IBM于1987年所提出的显示标准，所以后来的各种分辨率均以VGA的640×480为基准。比如，320×240称为QVGA（即VGA分辨率的1/4），400×240称为WQVGA（即宽屏QVGA），480×320的称为HVGA（即HalfVGA），800×600为XGA（即扩展VGA，在16bit色彩显示时，最高可支持1024×768），等等。

我们知道，分辨率越高，则图像显示越细腻，细节也越清晰。但是，如果脱离屏幕具体尺寸，泛泛而谈分辨率，是没有太大意义的。不妨假定有两个LCD，一个为3寸（英寸，以下同），另一个为5寸，并且它们的分辨率都是640×480。那么，从人眼观看的实际效果而言，它们的分辨率还一样吗？对于3寸屏来说，共有640×480个像素点均匀地分布在屏幕上，对于5寸屏来说，也是640×480个像素点均匀地分布在屏幕上。尽管它们的像素总数一样，但显然，在单位面积内，3寸屏的像素点数要高于5寸屏的像素点数，也就是说，单位面积内的图像，3寸屏的像素点阵更加密集，图像显示的效果自然也要更加细腻。

所以，越来越多的手机开始采用视觉分辨率来代替LCD的物理分辨率，其概念就是单位面积的像素点阵而已。

**2. 可视角**

可视角，是指在倾斜一定角度后观察LCD，会出现对比度变差以及画面失真。当画面失真达到可接受极限的时候，倾斜观察的角度被称为可视角。

将LCD的中心位置定义为原点，Y轴构成水平面，并按照逆时针方向，将水平面划分为3点、12点、9点和6点共四个方向，然后从Z轴方向倾斜一定角度0，观察LCD面板，

随着0的增加，图像对比度、失真开始恶化，直至可接受的极限。此时，倾斜角0就称为可视角。一般而言，LCD在6点方向的可视角最大（可达80°），在12点的方向可视角最小（约60°），3点和9点方向相同，介于6点和12点方向之间（60°~80°）。其实，我们仔细想一下用户手持机器观看屏幕的场景，就不难得出上述结论。

与自发光的CRT显示器不同，LCD采用照射发光机制，其本质是在LCD面板的后面放置照射光源，通过控制液晶分子的极化与偏振，改变照射源在液晶分子中的透射程度。而CRT是电子轰击荧光屏后向各个方向主动发光。所以，LCD存在可视角问题，而CRT基本不存在可视角问题。

**3. 色彩深度**

LCD面板上的任意一个像素，实际上是由R、G、B三个单色像素点组合在一起构成的。
所谓色彩深度，就是指每个R、G、B单色像素分别由多少bit来代表不同的色彩深度。比如一个色彩为16bit的LCD面板，其中R:G:B=5：6：5。也就说是，R有25种，G有20种，B有25种，它们组合在一起，一共可以显示216种色彩。如果R:G:B=6：6：6，则该LCD可以显示218种色彩，这也就是26万色LCD的由来。

不过，实事求是地讲，对于手机LCD来说，6.5万色和26万色，人眼看上去几乎是没有区别的。当色彩深度到达一定程度时，人眼对于色彩之间差别的分辨能力远不及对亮度、对比度的分辨水平。如果要想使一幅图像看上去清晰靓丽，最好的方法是提高显示器的分辨率以及图像的亮度、对比度，试图把色彩深度从16bit提高到24bit，则几乎没效果。在本书高级篇之“相机的高级设计”一章中，我们将对此问题做进一步讨论。

除了上述三个重要参数外，LCD还有响应时间、功耗等指标，但在手机设计中不是特别关注，有兴趣的读者可以自行查阅相关器件手册。

**4. 接口模式**

LCD与CPU之间的接口方式比较多，常见的有MCU模式、RGB模式、MIPI方式等。

MCU模式：实际上是把LCD看成外挂在CPU上的一个Memory而已，物理接口采用与Memory类似的CS/RD/WR/DATA等信号线，控制简单方便，无需时钟和同步信号。但需要耗费较多的GRAM，无法做到4寸屏以上。该接口目前在低端机中应用较多。

RGB模式：大屏采用较多的模式，按照RGB的位数，数据线长度有16bit、18bit、24bit等，还包括VSYNC（场同步）、HSYNC（行同步）、PCLK（像素时钟）等控制信号线。它的优缺点正好和MCU模式相反。该接口常见于中端机型。

MIPI模式：采用串行传输方式，接线简单，传输速率高（按当前的MIPI协议，一个Data Lane的最高传输速率可达1Gbps），特别适合大屏、高分辨率、高刷新率的LCD以及布线面积受限的机器。该接口常见于各种高端机型中。

最后，我们简要介绍一下OLED显示器，当前韩国三星公司在这一领域额居于领先地位。与LCD需要背光照射不同，OLED采用有机发光二极管，是在一种自发光方式的显示器。正由于自发光，OLED几乎没有可视角问题。另外，OLED内部是固态结构，而LCD是液态晶体，所以OLED的厚度更低（约为LCD的1/3），抗震性能也更好，响应时间更是只有LCD的千分之一，不存在任何动态拖影现象。但OLED工艺不够成熟，寿命只有LCD的一半，市场供应又被韩国人基本垄断，导致价格昂贵，供货周期较长。所以，OLED目前主要应用在一些高端超薄机型中。

#### 2.2.7 Acoustic

手机硬件中，与Acoustic相关的器件包括Microphone、Receiver和Speaker。

**1. Microphone**

常见的Microphone有数字Microphone和模拟Microphone两种。

数字Microphone一般采用硅工艺，一致性、抗噪性都比较好，但价格昂贵，基本上是模拟Microphone的3倍以上，在高端机型上应用较多。但随着工艺的发展，采用数字接口、模拟工艺的Microphone也越来越多。

模拟Microphone按照声一电转换原理，分为动圈式和电容式两种。

动圈式比较简单，对着Microphone 说话，空气振动带动Microphone内部的振膜跟着振动，而振膜上粘有导线并处于磁场当中，于是在导线中就产生感应电流，从而实现声信号到电信号的转化，说白了，就是闭合线圈在磁场中运动，产生感应电流。

电容式Microphone的工作原理不同于动圈式。在电容式Microphone的内部也有一个振动膜片，但它同时也是电容的一极，另一边为固定电极。对着Microphone说话，振膜振动，使电容器的间距发生变化，从而导致电容器的电容值和压降发生相应变化，再通过一个MOS管放大器将微小的电压变化进行放大，就实现了声信号到电信号的转换。不过，为了构成这个电容，电容式Microphone需要外加高压极化电压，使用起来不方便。于是，人们发明了驻极体Microphone，其内部振膜事先已经过高压电场充电极化，产生永久驻留在其表面的电荷，使用时就不需要再进行极化了。

由此可见，动圈式Microphone由于需要磁铁、导线等组件，体积比驻极体 Microphone要大得多，而且振膜上粘着线圈，质量大、惯性也大，导致灵敏度比驻极体的要低很多。所以，驻极体Microphone在手机产品中获得了广泛应用。顺便提一下，音频测试仪表多采用电容式Microphone，而非驻极体式。主要是因为驻极体Microphone随着使用时间的延长，灵敏度会出现不同程度的下降，这个缺陷对于检测仪表来说是不可以接受的。当然，一个高级的电容式Microphone，再配套放大器、高压极化电源，价格可不低。

图2-2-16为驻极体 Microphone的等效电路图（场效应管一般都集成在Microphone内部），从中不难看出，驻极体Microphone就相当于一个场效应管放大器。对于Microphone来说，有三个参数最为重要（仅指电气特性）。

![JDmtqH.png](https://s1.ax1x.com/2020/04/24/JDmtqH.png)

* 灵敏度

第一个参数，也是最重要的一个参数就是灵敏度，也即Microphone声/电转换能力。将Microphone 按照规定电路接通，放置于自由场中某一点（自由场、扩散场的概念牵涉到声学原理，有兴趣的读者可以查阅相关资料，本书不讨论），然后对自由场输入一个1kHz的正弦波信号，当Microphone所在的测量点声压为1Pa时，Microphone的输出电压即为其灵敏度（用dB表示，0dB=1V/Pa）。通常情况下，我们多选用灵敏度为-423dB的Microphone，该型号产品性能均衡，需求量大，所以价格也较便宜。

*  方向性

直观上，我们把手机Microphone正对自己和侧对自己说话，对方听到的声音大小肯定是有区别的。但是，这只是由于手机进音孔偏离声源，导致声音被送入Microphone之前就已经出现很强衰减了，并非Microphone自己衰减了不同方向的音源。但是，如果Microphone真的具有方向性，那么情况就又不一样了。此时，通过改变Microphone内部PCB或者外部音壳的设计，可以使Microphone自己有选择地衰减不同方向来源的声音，出现某些方向灵敏度高，某些方向灵敏度低的现象。这种指向型Microphone多用于车载电话、会议中心、蓝牙耳机等场景，可实现一定程度的降噪效果。常规手机中的Microphone为全指向型，也即无指向性。但要说明一点，指向型Microphone需要配合一定的腔体设计，否则会影响其效果。

* 输出信噪比S/N

测试条件与灵敏度相同。在手机中，该项指标多为58~60dB。一般情况下，我们对该指标并不是特别重视，毕竞手机Microphone只要求通话即可，并非录音棚，没必要要求那么好的器件。再说了，一个录音Microphone的价格恐怕够买10部iPhone了，老百姓谁用得起？

**2. Receiver/Speaker**

Receiver与Speaker统称受话器，只不过Receiver的额定功率远不及Speaker而已。目前，在手机中应用的受话器基本都为动圈式，其发声原理与动圈式Microphone也基本类似。振膜上粘有线圈并放置在磁场中，线圈通电后受力并带动振膜跟着振动，从而实现电信号到声信号的转化。

还有一种称为压电陶瓷的喇叭在部分便携式产品中也有少量应用，压电陶瓷喇叭便是利用陶瓷的逆压电效应，使附着在陶瓷表面的振膜随着陶瓷产生形变，从而推动空气发声。不过，为了获得足够的响度，陶瓷喇叭需要施加高压驱动，一般都要在12V以上，必须外加专用的驱动芯片。加上陶瓷喇叭本身成本就高出动圈式喇叭很多，所以在手机产品中很少采用。

#### 2.2.8 键盘与触摸屏

对于手机键盘，其原理与大家在微机课程中学习的一模一样，也是基于中断扫描方式的。

按下任意一个键，产生一个硬件中断，然后CPU执行中断处理程序，对键盘矩阵进行扫描，从而判断出到底是哪一个按键被按下，再转相应的按键事件处理程序即可。如果有多个按键被同时按下，处理过程也完全一样，根据扫描结果，转相应的复合键处理程序或者判定为无效按键后不处理。

图2-2-18是高通平台中的按键原理图，采用5×5矩阵方式链接。

![JDG178.png](https://s1.ax1x.com/2020/04/24/JDG178.png)

KEYPADX表示行线（Row），KEYSENSEX表示列线（Column）。在没有按键被按下时，行线全部输出低电平，列线全部输入高电平（通过内部上拉电阻实现），整个键盘扫描矩阵处于守候状态；若有按键被按下，假定为图中黑色圆圈所代表的按键，则对应的行线与列线连通，KSYSENSE3被KEYPAD11下拉至低电平，导致与非门KEYSENSE_INT产生一个从低到高的跳变，从而触发CPU中断。然后，CPU转入按键扫描程序，通过依次在各条行线输出低电平（某行线为低时，其余行线为高），并依次读取列线的状态，就可以定位出到底是哪一个或哪几个按键被按下了。

随着触摸屏产业的迅速发展，不仅智能机，普通功能机也开始越来越多地采用触摸屏代替键盘，作为人机输入设备。按照实现原理，触摸屏分为电阻式、电容式、表面声波式、光学式和电磁式等多种，但在手机产品上基本只有电阻式和电容式两种。将触摸屏按照行、列画线的方式分割成一个个小的矩形区域，然后采用与键盘扫描类似的技术就可以定位触点坐标（可参见后面的图2-2-19）。

过去，触摸屏多采用电阻式。用手或者笔按压触摸屏，按压点附近电阻网络被短接，经A/D转换后得到按压点的电压，从而间接定位出触点位置。现在，触摸屏多采用电容式，并越来越多地采用互容式电容屏（另一种为自容式）。用手接触屏幕，将引起屏幕触点附近的电

容值发生变化，而容值的变化又会导致其充放电时间常数随之变化，从而间接定位出触点的位置。一般而言，电容屏相比电阻屏有如下特点：

（1）电容屏的灵敏度要高于电阻屏；

（2）电容屏通过检测容量变化来定位，只要距离靠近而无需压力，其寿命远超电阻屏；

（3）电容屏可以很容易地实现多点触控，而电阻屏依靠压力定位，实现诸如放大、缩小等手势触控比较困难。

（4）如果屏幕上有水珠，会导致电容屏的容值变化量减小，灵敏度显着下降，而电阻屏完全没有影响。所以，即便IP67防水标准的电容屏手机，在水下触控也很难实现。

#### 2.2.9 蓝牙

蓝牙工作于2.4GHz频段，采用跳频方式，即载波频率按照伪随机码序列变化，从一个信道快速跳到另一个信道上，从而实现扩频通信（与蓝牙的扩频通信原理不同，CDMA采用DSSS高速地址码调制方式实现扩频）。截至2012年，蓝牙已演进到最新的4.0版本规范，但应用肯定是滞后于规范的。所以，目前市场上的手机大部分还在使用3.0版本的蓝牙设备。其实，3.0也好，4.0也罢，优化升级主要集中在协议栈层面，对我们硬件研发工程师来说，区别不大。

按照通信距离，蓝牙设备分为ClassA和ClassB两类。ClassA的传输距离可达100m，但因其成本高、功耗大，在手机等便携式设备上鲜有采用。ClassB的传输距离大约为10m，体积和耗电都比较小，在手机和各种蓝牙耳机上获得广泛应用。按照2.0版本规范，蓝牙的数据传输率为2Mbps；3.0版本规范基于802.11协议，可支持高达24Mbps的传输率。并且除了支持常规的数据传输外，它们还都支持立体声音乐传输。

下面，我们以图2-2-20所示的高通平台自带的蓝牙芯片BTS4025为例，对蓝牙模块进行介绍。

从图2-2-20中可以看出，BTS4025内部由三个模块组成，一个Baseband模块，一个Analog RF模块，另一个是Power Management模块。

Power Management模块很好理解，输入电压经过该模块后输出各路电压，给芯片的其他部分提供所需电源。

Baseband的功能较为复杂，主要由三个部分组成。第一个部分是Modem模块，用于实现基带数据的调制/解调。在第1章中我们曾介绍过，蓝牙支持GFSK、$\pi$/4DOPSK及8DPSK调制方式。那么，把数字信号调制在基带载波上或者把基带已调信号解调为数字信号，都是在该模块内完成的。第二是时钟模块，用于时序控制。BTS4025有两路时钟源，一个快时钟，可用系统的19.2MHz或者外接晶体（按芯片手册要求，可以是19.2MHz，也可以是32MHz）；另一个慢时钟，可以使用系统提供的32.768kHz或者外加一个32.768kHz的晶体实现。快时钟主要用于正常工作状态，如频率合成、接口控制等，慢时钟则用于芯片Sleep状态，可实现降功耗、中断唤醒等功能。第三部分则是Processor与I/O接口，用于芯片状态控制、GPIO控制、音频PCM数据流控制等各种功能。

![JDdhzF.png](https://s1.ax1x.com/2020/04/24/JDdhzF.png)

AnalogRF为模拟射频模块，它将Baseband Modem发送过来的I/Q两路基带已调信号直接上混频到2.4GHz，然后经PA放大发射出去；或者把天线接收到的2.4GHz高频载波经LNA放大后，再下混频为基带已调信号，分为I/Q两路送到Baseband Modem中去进行数字解调。至于混频所需的本振源，则由Frequency Synthesizer提供，采用PLL电路实现。

通过这番分析，我们可以看出，蓝牙芯片其实就是一个微型的无线电电台，手机所具备的无线通信功能，都在一个小小的蓝牙芯片中全部实现了。尽管它们采用的技术各不相同，但从无线电电台的架构上看，没有本质区别。读者朋友可以把BTS4025与图2-1-1所示的手机硬件架构图进行对比，两者完全一致。

#### 2.2.10 FM Radio Receiver

广播电台分为中波电台（如南京新闻台AM1008）、短波电台（如VOA、BBC，其播送频率、时间等会随着季节更替、政治风云而发生变化）、调频电台（如FM89.7江苏音乐台）。一部全波段收音机，可以接收上述所有中波、短波和调频广播电台（部分低成本收音机只能接收FM广播电台，常见于各类地摊），但对于手机，哪怕是Samsung Galaxy，也都只能接收调频广播电台（iPhone居然不支持FM广播电台，除了商业原因外，我实在找不出其他原因了）。

中波电台、短波电台，是指该电台所发射的电磁波波长，如我国中波电台的频率范围为585-1600kHz，对应的波长范围为500-200m；短波电台的频率范围为2-20MHz，对应的波长范围为150~15m。而所谓的调频广播电台，则是指该电台采用的是频率调制技术，与电磁波波长没有任何关联。所以，中波、短波电台代表一个概念，而调频代表另一个概念。

在我国，调频广播电台的频率范围为88~108MHz，对应的波长范围为3.4～2.8m。可见，FM广播电台的波长远比中、短波广播电台要短得多。而之所以手机无法接收中、短波电台，则是由于手机体积有限，很难设计出可以接收中、短波电台的天线。进一步的讨论，读者可以参考提高篇中的“FM立体声接收机”一章。

随着集成电路工艺的迅速发展，现代手机中的FM接收机只需要一颗芯片，再配以简单的阻、容、感器件就可以实现了，如某型号手机中的FM接收机原理图如图2-2-22所示。

![JDBQ2T.png](https://s1.ax1x.com/2020/04/24/JDBQ2T.png)

#### 2.2.11 Wi-Fi

Wi-Fi，全称为Wireless Fidelity，即无线高保真。实际上它是一种基于IEEE 802.11协议的无线传输兼容性认证，也就是说，Wi-Fi是一种商业性认证，但更多的时候，我们就用它指代一种无线联网方式。过去，我们利用有线电缆的形式，将PC等设备接入网络；现在，随着

移动通信设备的快速发展，则可以采用无线传输的形式，非常便捷地将PC、手机、PAD等设备接入网络。

相较于传统的有线局域网（LAN），采用无线通信接入局域网的方式就被称为WLAN，而Wi-Fi其实就是支持WLAN的一个协议标准而己。早在2001年，中国就开展了无线局域网安全技术的研究，并在同年提出自己的标准草案。到2003年，我国政府正式批准了具有我国自主知识产权的WLAN标准——WAIPI（常简写为WAPI）。随后，经历了一系列强制实施、全球投票、协商谈判等波折，WAPI终于被国际标准化组织ISO接纳为WLAN标准之一。不过，就目前的实际情况而言，Wi-Fi依然是真正的市场霸主，而WAPI却不得不面对有标准、无产品的尴尬局面，甚至有被最终边缘化的可能。

从另一个角度看WAPI与Wi-Fi之争，有一点TD与UMTS和EVDO对抗的味道。但国家强迫中国移动运营TD网络，则给了TD以极大的生存空间，WAPI要想获得发展，似乎也可以借鉴TD的做法。因为在笔者看来，不管技术水平到底如何，中国在标准问题上必须要有话语权。

从通信电路上分析，Wi-Fi芯片与蓝牙芯片一样，都是数字调制/解调—→RF混频一→天线发射/接收的架构，并且Wi-Fi也工作于2.4GHz频段。于是，Wi-Fi芯片与蓝牙芯片就可以共享RFPA、BPF和天线，而仅仅是在通信协议上有所区别。所以，越来越多的平台以及第三方芯片，都把Wi-Fi与蓝牙集成在同一颗芯片内，有的甚至会把FM接收机也一并集成进来，以进一步降低成本，如TI公司的WL1271就是一颗802.11Wi-Fi+蓝牙+FM的三合一芯片，如图2-2-23所示。

![JsmQGq.png](https://s1.ax1x.com/2020/04/25/JsmQGq.png)

#### 2.2.12 GPS

GPS系统由24颗卫星组成（2006年3月时为28颗），分布在6个圆形轨道上，轨道相对赤道的倾斜角为55°，沿赤经以60°间隔均匀分布，半径26560km，环绕地球一周约为半个恒星日（11.976h），可覆盖全球98%以上的面积。每颗卫星都携带一个为卫星发射信号提供时间信息的绝原子钟和（或）物原子钟，其内还含有时钟校正系统，原子钟基准频率为10.23MHz。每颗卫星发射两个L波段的扩频载波信号，其中L1的载频为1575.42MHz，L2载频为1227.60MHz。一般，民用接收机只接收L1载频信号。

#### 2.2.13 G Sensor

G Sensor，全称为Gravity Sensor，即重力传感器，有时也称Accelerator Sensor（加速度传感器）。顾名思义，GSensor用于检测加速度的方向与大小，等效于检测手机的运动状态，如横屏与竖屏的自动切换。

以Bosch的BMA250三轴加速度传感器为例，它可以选择SPI或者PC总线接口，2个中端输出管脚，低功耗、低唤醒时间，其内部框图如图2-2-25所示。

X、Y、Z分别表示三个轴向的传感器，当GSensor以加速度a运动时，内部三个轴向传感器受到一个与加速度方向相反的惯性力作用，发生与加速度成正比的形变，使悬臂梁随之产生形变。该形变被粘贴在悬臂梁上的扩散电阻感受到，根据硅的压阻效应，扩散电阻的阻值发生与形变成正比的变化，将这个电阻作为电桥的一个桥臂，通过测量电桥输出电压的变化就可以完成对三个轴向加速度的测量。然后把电桥输出电信号送入前置放大器，经过信号调理电路改善信噪比，再经过A/D转换得到数字信号，最后送入CPU进行处理。

![JsQOxI.png](https://s1.ax1x.com/2020/04/25/JsQOxI.png)

#### 2.2.14 E-compass

E-compass，即电子罗盘，俗称指南针。利用E-Compass，手机可以实现对东南西北的方位指示。

由于E-compass对磁场较为敏感，所以在器件布局时，要尽量避免将E-compass芯片摆放在诸如Speaker这样的磁性较强的器件或者芯片附近，防止这些器件对E-compass产生干扰，导致功能失灵。

#### 2.2.15 Light Sensor与Proximity Sensor

在业内，我们通常把Light Sensor简称为LSensor或光感，而把Proximity Sensor简称为P Sensor。

LSensor用于检测周围环境光的强度，然后CPU可以根据检测结果自动调整LCD背光强度。比如在白天的室外，光线较强，则CPU自动把LCD背光调亮，方便用户看清LCD内容；晚上的室外光线弱，则CPU自动把LCD背光调弱，以节约电量。

P Sensor 则用于检测与某物体的接近距离。通话中，当用户手持机器贴近人脸后，PSensor检测到被人脸所反射的光线（实为PSensor发射的红外线被人脸所反射），就通知CPU关闭LCD背光显示，节约电量。

目前，L Sensor与PSensor通常都做在同一个模组里面，有的甚至会把红外发射管也集成在模块内部。一个实际的L+P Sensor（含红外线发射二极管）的模块框图如图2-2-29所示。

![JstY3F.png](https://s1.ax1x.com/2020/04/25/JstY3F.png)

IR表示红外线，ALS表示环境光，分别由各自的光电二极管接收。我们知道，可见光的波长分布在400-700mm，而红外光的波长在800~4000mm。所以，这两种光电二极管对应的接收波长自然也就不一样。一般，ALS光电二极管峰值效率所对应的接收波长大约为550nm，而IR光电二极管峰值效率所对应的波长大约为850mm，如图2-2-30所示。

![JstXbn.png](https://s1.ax1x.com/2020/04/25/JstXbn.png)

与此同时，模组厂在生产时，还会在红外发射管与接收模块的外部封装一组透镜（肉眼很难分辨），一方面可以起到聚光作用，提高发射/接收的效率；另一方面可以增加一些滤旋光性能（即滤除光电管接收波长范围以外的电磁波）。

一般而言，PSensor的设计难度比LSensor要大。毕竟，PSensor还涉及红外发射，要想实现稳定可靠的工作，必须注意杂散光、可视角、透光率等指标，并配合良好的结构设计。

下面，我们简要介绍这几个指标。

**1. 杂散光**

在实际使用中，IR发射二极管的发射信号常会打到一些非目标物体，并反射回PSensor中。这些信号都不是我们想得到的，称之为杂散光。在PSensor设计中，最常见的杂散光主要是IR发射二极管发射到Cover Lens后反射回PSensor的杂散光，还有就是通过缝隙漏到P Sensor的杂散光，如图2-2-31所示。

![JsN5L9.png](https://s1.ax1x.com/2020/04/25/JsN5L9.png)

**2. 可视角与发射角**

可视角指的是被测物体能被侦测到的最大角度，也就是说超过这一最大角度的物体是无法被侦测到的，由于结构设计等方面的局限性，可视角的大小普遍在30°~50°。直观上我们不难想象，光电二极管的可视角与IR发射管的发射角越大越好，并且光电管的可视角要大于等于IR发射管的发射角。

一般来说，光电接收管可视角不小于45°，IR发射管的发射角不小于35°。

**3. 透光率**

Cover Lens通常会选用高透光率的材质，但出于美观考虑，会在表层涂上深色油墨，从而影响LSensor与PSensor的灵敏度。所以，此种油墨的透光率也是我们在设计时必须考虑的。

通常，可见光透光率应大于10%（以550nm为基准），红外光透光率应大于80%（以850nm为基准）。

**4. 结构设计**

（1）IR发射管、光电接收管到CoverLens的距离要尽量小，从而扩大可视角。

（2）Cover Lens 上的油墨应涂于下表面，减少二次反射。

（3）隔离IR发射管与光电接收管之间的Rubber要密封，并且Rubber要有足够的预压量，减少通过Rubber缝隙漏光的可能。

（3）IR发射管和光电接收管的可视角交点尽量在Cover Lens之上，以减小杂散光影响。

在此，提醒读者一点，任何产品的设计都是一种相互妥协、折中考虑的过程，特别是当结构设计与电子设计不能同时满足的情况下，应注意把握主要矛盾，忽略次要影响。比如可视角越大，灵敏度越高，但杂散光的影响也可能越厉害。此时，我们可以优化判定门限，在灵敏度和误判断之间取得平衡。

#### 2.2.16 Gyro Sensor

Gyro Sensor，即陀螺仪。陀螺仪的名称来自法国物理学家莱昂·傅科（J.Foucault），他在1850年研究地球自转时发现，高速运动中的转子具有惯性，其旋转轴始终指向一个固定的方向。于是，傅科便用希腊字母gyro（旋转）和spokein（看）两个合在一起组成Gyro Scopei来命名这种仪表。

陀螺仪在发明初期由机械装置构成，主要用于航海导航，而现代陀螺仪则包括光纤陀螺仪、激光陀螺仪、MEMS陀螺仪、振动式陀螺仪等各式各样的陀螺仪，并在航空航天、自动控制等领域获得了极为广泛的应用。实事求是地讲，陀螺仪是一门十分高深的学问，很多专业知识也大大超出了笔者的理解层面。所以，本书只能对陀螺仪在手机中的应用做一番简单介绍。

我们已经知道，利用加速度传感器，手机可以感知X、Y、Z三维方向的直线运动。但是，手机如何感知旋转方向的角速度运动呢？这就要用到陀螺仪了。

在手机中，陀螺仪均采用MEMS工艺制作。它可以很方便地检测出旋转运动的角速度、角位移，测算出物体的俯角、仰角等参数，从而实现诸如航向指示、姿态确定等功能。运用到手机中，比如各种赛车类游戏，软件可以借助陀螺仪的角运动计算，实现用户对车辆转弯、加速等状态的操控。当然了，并不是每款手机都配备Gyro Sensor，在一些手机产品中，利用加速度传感器也可以实现一定程度的角运动计算（毕竟，加速度传感器并不会总位于手机的中心位置，所以当手机出现角速度运动时，总可以分解出一定大小的/Y/Z三维方向的直线运动），但精度比起陀螺仪来要差很多，且一旦运动停止，加速度传感器就不能够再提供任何角位移等方面的有用信息了。

#### 2.2.17 SIM卡



SIM卡，即用户识别模块，在CDMA系统中也被称为UIM卡。

SIM卡与手机一起构成了移动通信终端设备。通常情况下，GSM系统、CDMA系统、或其他系统，都会为办理入网业务的手机用户提供一张存储有相关数据信息的SIM卡。

一般，SIM卡的信息分为两类：一类是由SIM卡生产厂商和网络运营商写入的信息，包括生产厂家代码、网络鉴权与加密信息、用户号码、呼叫限制等；另一类是由用户在使用中自行写入的数据，包括联系人号码、用户设定的个人识别码（PIN）等。

通过SIM卡的使用，手机可以不固定地属于一个用户，实现手机号码“随卡不随机”的功能。于是，运营商的收费也是随卡不随机。不过，有些运营商在为新用户办理入网业务时，会有一些优惠措施，比如入网送手机，而所送手机只能选择该运营商网络。那么，这些手机也可以不需要SIM卡，因为相关信息已经事先写入到手机里面了。另外，检测SIM卡是否存在通常只在开机瞬间完成（取决于具体的平台）。所以，如果由于卡座接触不良导致开机后未检测到SIM卡，必须重新插拔并开机。

SIM卡接口电路图比较简单，如图2-2-32所示。图中，VCC是电源电压，常为3V或者1.8V；RST是复位信号，高电平有效；CLK是SIM卡的时钟，3.25MHz；I/O则表示SIM卡的双向传输数据接口。

![JsbtRP.png](https://s1.ax1x.com/2020/04/25/JsbtRP.png)

### 2.3 手机的电源系统

#### 2.3.1 系统电源与外设电源

整个手机的电源系统分为两大块，即系统电源与外设电源。系统电源包括电池的Vbat电源、CPU内核电源、CPU与Memory的接口电源、RTC电源、RF Transceiver电源等；外设电源则包括LCD电源、VC-TCXO电源、音频输入输出电源、FM/BT/GPS/Camera电源等。

一般而言，系统电源在待机状态不会下电，但外设电源在待机时基本处于下电状态，以降低系统功耗。当然了，这个也不是绝对的，有些外设芯片会由几路不同的电源供电，如果单独对某一路电源下电，反而可能造成芯片馈电。

在手机电路中，不同的芯片对电源的要求也各不相同。按照电压高低，CPU的内核电压基本在1.2V左右，Memory和GPIO的接口电压多为1.2V或1.8V，各个Sensor的模拟电源多为2.8V等；按照电流大小，RTC大约0.1mA，CPU内核平均电流能达到300-500mA，GSMPA的瞬间电流则可能超过1A；按照待机时的状态，Memory接口电压常在，CPU内核电压则可以在1.1~1.3V波动（睡眠为低电压，唤醒后为高电压，以实现功耗动态管理），1Pc接口电压则可能完全关闭。所以，针对不同的需求，我们需要注意以下几点：

（1）电源开关是否可控？

（2）电源的最大输出电流是否满足负载所需？

（3）电源输出电压是否可调？

图2-3-1为某手机处于待机状态下，其26MHz主时钟VC-TCXO的供电电源波形。从图中可见，该电源在系统休眠时关闭，在系统唤醒时打开，从而降低系统功耗。

![JsOm2q.png](https://s1.ax1x.com/2020/04/25/JsOm2q.png)

说明一点，图2-3-1中的电压下降波形呈指数函数形状，乃是电源关闭时由电容放电所致。理论上，电源打开，电容充电的上升波形应该呈指数函数形状，只是由于电源打开时的电容充电线路阻抗远远小于电源关闭时电容放电线路阻抗，所以充电时间常数很小，电容几乎在瞬间就被充到了电源电压上。

#### 2.3.2 电源的分类

前面，我们按照电源所带负载的类型，把手机电源分为系统电源与外设电源。但就电源本身而言，应该如何分类呢？

如果读者看过一些原理图就不难发现，手机中的电源除了由PMU芯片提供外，有时也会额外使用一些电源芯片，如所谓的“LDO”、“DC-DC”等。其实，PMU内部的电源模块基本上也都是由LDO与DC-DC构成。

LDO是线性电源，纹波小、效率低，主要用于对噪声比较敏感的负载供电，如音频电路、各种Sensor模拟电路、RFLNA等。

DC-DC是开关电源，纹波大、效率高、带载能力强，主要用于给大功率负载或者数字电路供电，如CPU内核、Memory等。

### 2.4 手机中的常用接口

手机中，各个芯片、模块之间的控制与通信，均要通过一定的接口电路实现，如SPI接口、MIPI接口、I$^2$C总线、Memory总线等。如果将这些接口进行分类，则可以分为总线型接口和非总线型接口。

本节对这些接口进行初步探讨。

#### 2.4.1 总线型接口

总线，即英文Bus。其实，不仅在芯片和模块之间存在总线，在芯片的内部，比如CPU，也有各种各样的总线。不过，我们并不关心芯片内部的总线，而仅仅探讨芯片、模块之间的总线，这些也是我们手机硬件工程师可以亲眼目睹并直接处理的物理传输线路。至于芯片内部的总线，就不在我们的讨论范围了。

根据数据的逻辑意义，总线分为数据总线、地址总线、控制总线等。有的系统中，数据总线和地址总线共用同一组物理传输通道，如80C51单片机中，数据总线和地址总线复用PO/P2接口，手机的NANDFlash也是数据总线和地址总线复用同一组I/O接口，而SDRAM的地址总线与数据总线则是物理分离的。

评价总线性能有如下几个指标。

（1）总线宽度Width按照数据传输的方式，总线分为串行总线与并行总线。串行总线的代表是PC与USB，并行总线的则很多，如SDRAM的各种总线、NANDFlash的总线等。
很显然，在传输速率相同的情况下，并行总线数据线根数越多，则单位时间内的传输数据量越大。所以，我们把并行总线宽度又称总线位宽，即能同时传送数据的二进制位数，单位为（bit）。串行总线的位宽为1bit，并行总线位宽通常为8、16或32bit。

（2）总线频率Freq总线频率是总线工作速度的一个重要参数，是总线实际工作频率，指一秒能够传送数据的次数，通常用Hz来表示。总线频率越高，工作速度越快。

（3）总线带宽BW总线带宽即总线的数据传输速率，是指每秒总线上可传送的数据总量，通常以MB/S为单位。总线带宽由总线的宽度与总线的频率共同决定，如下式定义：
$$
BW=(Width/8)*Freq
$$

#### 2.4.2 非总线型接口

上一节，我们介绍了与总线有关的一些概念。

在手机中，常见的总线有USB（串行）、EB11或EBI2（高通定义的一种并行总线，用于CPU与外部存储器芯片之间进行数据交换）、I$^2$C（串行），等等。那么，SPI、UART、MIPI等，它们也是总线吗？

想想平时，我们也常常把SPI称为SPI总线，把MIPI称为MIPI总线。但实际上，这些接口并不是总线型！

通过对总线的介绍，我们会发现总线除了具备共享性和分时性，其最大的特点是寻址。

各个模块单元可以共用地址线、控制线和数据线，但必须通过寻址来与目标器件建立通信、传输数据。而SPI、UART、MIPI等接口并不存在寻址，它们与CPU之间仅仅通过一定的通信协议来传输数据。

以I$^2$C总线为例，一组总线（由数据线SDA与时钟线SCL组成）上可以同时挂多个器件，如图2-4-1所示。在手机I$^2$C电路中，一般只有一个主控器件Master（通常为CPU），其他都为从控器件Slave（如E-Compass、Gyro Sensor等）。通信过程由Master发起，向目标Slave发命令。众多Slave都会接收到Master的发起命令，但只有地址相符的Slave才会响应Master的命令，其他地址不符的Slave则依旧保持沉默。由此可见，当多个器件挂在同一组总线上时，为了避免总线访问冲突，必须进行寻址。而如果是多主总线（I$^2$C实际上是支持多主操作的），则当多个Master同时发起总线访问时，必须经由仲裁器进行访问仲裁，确定到底由哪一个Master 占用总线，才能确保总线的互斥操作。用计算机操作系统的专业术语来说，就是对资源的互斥访问，可以用PV原语描述（最常见的PV原语用于进程通信中的同步与互斥）。

![JyPh3F.png](https://s1.ax1x.com/2020/04/25/JyPh3F.png)

那么，我们查查SPI、UART、MIPI等接口协议就不难发现，尽管它们也是独占通信线路的，但它们没有寻址概念。所以，从这个意义上说，它们都是非总线型接口。

但是，总线与非总线也不是完全对立的。以SPI接口为例，我们知道SPI接口通常由4根信号线组成，分别是时钟SCK、输入数据DIN、输出数据DOUT和片选CS。在通信发起前，CPU必须首先使器件的CS保持有效。如果CS是连接在CPU的GPIO上，那么只要对GPIO置高或者置低就可以了，显然不存在寻址一说；但如果CS不是连接在CPU的GPIO引脚上，而是连接在CPU的地址线上（一般还要加编码器和地址锁存器），通过地址线使CS有效，这样就有寻址概念了。换言之，如果GPIO本身可以通过内存的地址空间进行映射，那CS就会有寻址的概念。

事实上，这种将CS与地址线连接的设计，在80C51等单片机系统中很常见（由于手机CPU的GPIO数量较多，所以手机电路从不这么做）。其好处是可以让CPU对外设进行寻址，并采用与访问内存空间一样的方法进行外设访问，缺点就是外设会占用内存的寻址空间，使系统支持的最大内存容量减小（但毕竞外设数目是非常有限的）。笔者读研究生时设计过的一个电路就是采用该方案，把CPU启动A/D、获取采样数据的过程抽象成对内存的一次读操作，代码非常简洁。

因此，总线型接口与非总线型接口，也不是那么绝对的。作为手机硬件研发工程师，也不一定要严格区分它们，但多了解一些总归没有坏处。

### 2.5 手机中的关键信号

手机中的信号线各式各样。按照电压/功率大小划分，有小信号如RF Input、Current Sense等，有大信号如PA Output等；按照数字/模拟划分，有数字信号线如GPIO、SDIO等，有模拟信号线如Acoustic、OSC等；按照信号频率划分，有低速信号如PCM Stream、1Pc等，有高速信号如USB、MIPI等；按照信号用途划分，有数据信号如RGB、Memory等，有控制信号如Enable/Disable、Interrupt等。

尽管有各种信号，但对于任何一个电子系统来说，都有关键信号和非关键信号之分，并且只有处理好那些关键信号，才可能设计出一个性能优秀的产品。本节主要介绍手机系统中的一些关键信号。

#### 2.5.1 Acoustic 信号

很多硬件工程师刚刚入行的时候会想：音频不就是出声音嘛，有什么了不起的？殊不知，麻雀虽小，五脏俱全。手机音频也是一个系统工程，涉及电声器件、音腔设计、电路设计、PCB走线设计、数字信号处理等一系列技术，别说是随便搞搞了，就是用心设计、仔细考虑、精挑细选，都不一定都达到满意效果。毕竟，手机的体积、成本、造型都摆在那里，不是我们想怎么搞就可以怎么搞的。

此处，我们单就电路设计、PCB走线设计及器件参数选型，着重讲解几个需要特别留心的地方。

**1. 差分线设计**

![Jy8sKA.png](https://s1.ax1x.com/2020/04/25/Jy8sKA.png)

图2-5-1为手机中最常见的Microphone电路，其中MicBias表示偏置电压（一般在2V左右，常为1.8V），Re、Ra为偏置电阻，C1、C2为隔直电容（亦为交流耦合电容），Amp表示差分放大器，Vad、Ve是其正负电源（目前，大部分的放大器均采用单电源供电，也即Vee为0），N、P则分别表示Microphone本体的两个焊盘。通常，差分放大器是集成在虚线框所示的Codec（Code Decode的英文缩写，表示音频编解码器）芯片内部的。

在前面的2.2.5节我们介绍过，手机中的驻极体Microphone相当于一个场效应管放大器，所以用一个场效应管代替图2-5-1中的Microphone就很容易知道，经过C1的电压信号与输入信号反相，通过C2的电压信号与输入信号同相。

进一步分析，如果R。=Ra，则Mic_N与MicP大小相等，极性相反。于是，这就构成了一个典型的差分放大电路。

如果ReeRa，则MicN与MicP大小不等，但极性相反。于是，就构成了一个“伪差分”
放大电路。此时，通常的情况是使Ra=0（即P点直接下地）。因为Microphone的金属外壳基本都与焊盘P连通，如果把Microphone的金属外壳接地，有利于提高Microphone的抗噪性能（尤其是天线的高频辐射干扰）以及提高ESD性能。尽管此时Mic_P上没有信号而只有地线噪声，它不是一个真正的全差分电路。但Mic_Bias为电源，相当于交流接地，所以地线噪声可以通过Mic_Bias→Rc→Mic N的通路，同样实现对地线噪声的共模抑制，故称“伪差分”。

实际的情况是，这两种电路形式在手机设计中都有广泛应用。

**2. 信号线保护**

我们知道，音频电路属于模拟信号范畴，尤其对于Microphone的小信号，幅度只有100~200mV，极易受到干扰。

所以，对于音频信号线来说，在PCB布线的时候必须做好各种保护措施，如信号线包地、模拟地和数字地隔离、单点接地等。除此以外，在器件布局时期，就应该注意尽量让音频信号线远离RF PA、CPU Core电源等大功率器件以及Clock之类的开关器件，从而远离各种可能的干扰。

**3. 额定功率**

对于Receiver和Speaker来说，一定要确保芯片或功放输出信号的功率处于器件额定功率

范围内，否则就有损坏器件的风险。这一点很好理解，但有个问题比较棘手，即如何定义器件的额定功率？

假如功放输出的音频信号都是单音正弦波，那这个问题就很简单了。对Speaker 输入固定功率的单音信号，测量其SPL（Sound Pressure Level）与THD（Total Harmonic Distortion），连续工作72h后再次测量SPL与THD，并与第一次测量结果对比。如果两次测量数据的变化范围在3dB内（可由厂家定义或共同协商制定），便认为器件可以承受，然后增加输入功率，直至极限。

但实际的情况是，功放输出的音频信号不仅幅度在时刻变化，其频率成分也在时刻变化。比如有两个单音信号，幅度相等，但一个频率为1Hz，另一个频率为1kHz。幅度相等，说明两个信号的功率一样，那么不妨假定它正好等于Speaker所标称的额定功率。现在，如果把它们分别送入同一型号的Speaker中，会产生什么结果？基本上，在很短的时间内，输入1Hz信号的那个Speaker多半会在几分钟内烧毁，而1kHz的那个在长时间工作后依然安然无恙。原因很简单，1Hz的信号频率对于Speaker来说实在是太低了，几乎相当于直流信号，会导致Speaker内部线圈严重发热最终短路烧毁。

由此可见，Speaker的额定功率肯定不能采用单音信号测试的结果。另外我们知道，无论语音还是音乐，总是处在一个频段范围内，如语音基本在300-4000Hz，而音乐大约在100~10000Hz。所以，对于受话器的额定功率测试，就要考虑输入信号的频谱范围，用单音信号测量显然是不合适的。在实际测试中，我们总是利用随机信号发生器生成一个覆盖 Speaker工作频段的宽带随机信号（此宽带是相对于单音信号而言的），由于信号为随机的（幅度、频率皆随机变化），所以信号的功率只能用平均功率来描述（可通过音频交流毫伏表测量）。然后采用与前面介绍的单音信号测量完全相同的方法，就可以测出比较接近真实使用情况的Speaker额定功率。

进一步地，同样带宽、同样平均功率的两种随机信号，它们各自频率成分占平均功率的百分比可以不一样，比如白噪声（White Noise，功率谱密度为常数，不随频率变化）与粉红噪声（Pink Noise，功率谱密度随频率的上升每倍频程下降3dB）。由此不难看出，粉红噪声中的低频成分占总功率百分比要大于高频成分。

经过大量研究，人们发现，语音、音乐等模拟信号的功率谱与粉红噪声比较接近，且峰值因素为3（峰值因素，即Crest Factor，定义为峰值与有效值之比，所以也常被称为“峰均比”）。所以，在受话器/扬声器测试中，应使用峰值因素为3的粉红噪声来模拟实际通话、播放音乐等场景。不仅是额定功率测试，而且在声压频响、灵敏度、谐波失真等参数测量中，使用粉噪要比单音信号更加接近真实情况。

如果将峰均比的概念进一步推广，我们还可以得到CCDF（Complementary Cumulative Distribution Function）的概念。我们知道，峰均比其实是信号峰值与均值（有效值）之比，但它并没有考虑到峰值或者瞬时功率的出现概率，换言之，峰均比并不能告诉我们信号统计方面的信息。比如，信号瞬时功率比均值高于3dB的概率是多少？

因此，人们引入了CCDF（互补累积分布函数，其数学本质为信号的统计描述）。首先，假定我们知道了信号功率的概率密度分布函数（Probability Density Function，PDF），即信号瞬时功率围绕其平均功率波动的概率密度分布情况；然后，我们可以对PDF进行积分，从而计算出信号瞬时功率的累积分布函数（Cumulative Distribution Function，CDF）；最后，对CDF做“模1加”就得到CCDF，即CCDF=1-CDF，故称为Complementary CDF。上述过程，可用图2-5-2表示（摘录自Agilent文档）。

![JyUgVs.png](https://s1.ax1x.com/2020/04/25/JyUgVs.png)

只需要说明一点，在CCDF图中，横坐标表示信号瞬时功率与其均值的差距，记为4，可正可负，单位为dB；纵坐标表示瞬时功率比均值高4的累积概率（简称“概率”）。比如从图中可见，瞬时功率比均值高1dB以上的概率P（4≥1）大约为0.15，瞬时功率比均值高-1dB以上的概率P（d≥-1）约为0.85（因为本图中PDF是对称的，所以P（4=-1）=1-P（4≥1）），而瞬时功率比均值至少低1dB的概率则为0.15，即P（d<-1）=1-P（d≥-1）。

仔细想一想，我们就不难发现，Crest Factor关注的仅仅是信号的瞬时峰值，而CCDF关注的则是信号瞬时功率相对于均值的分布情况，所以CCDF肯定可以比Crest Factor体现出更多的信息。事实上，CCDF在RF性能分析中已经获得了广泛应用，尤其是采用线性射频功放的CDMA系统。关于CCDF的进一步讨论，笔者就不在入门篇中展开了，可参阅本书提高篇的“常规RF性能指标”，有兴趣的读者也可以在网络上搜索一下Agilent的这篇文档“Characterizing Digitally Modulated Signals with CCDF Curves”，写得非常不错！

现在我们知道，只有结合Crest Factor和CCDF，才能够对音频信号进行较为完整的分析。但实际情况却是各个手机生产设计厂家对额定功率的定义与测试方法都不统一，各个电声器件生产厂家的定义也各不相同（笔者目前尚未见到哪个电声厂家引入CCDF）。一般而言，同样功率的粉噪与白噪，由于粉噪所包含的低频信号成分比白噪更多，所以用粉噪测试受话器参数要比白噪更加苛刻。所以，在查阅厂家SPEC时，一定要注意测试条件，最好能与厂家确认。前面所介绍的Speaker额定功率测试方法，就是笔者与山东潍坊某电声器件生产厂家在合作多年后共同商定的结果（简化了一些内容）。

#### 2.5.2 I/Q信号

1/Q信号是通信系统中一个重要概念。在手机设计中，I/Q信号质量也是需要工程师重点关注的地方。

I是指In-phase，即同相，Q是指Quadrature，即正交。在第1章介绍CDMA码分多址系统时，我们曾经以笛卡儿三维坐标系为例解释过，X/Y/Z三个坐标轴，两两垂直便称为相互正交。那么，假定有一个向量L由X、Y、Z轴方向的三个坐标值决定，并且认为X轴为同相分量，那么Y轴与z轴都可称为正交分量。

将上述概念推广至通信系统中，一个数字已调信号$S_m(t)$通常可以写为
$$
S_m(t)=S_I(t)\cos\omega _ct+S_Q(t)\sin\omega_ct
$$
由于$\cos\omega _ct$与$\sin\omega _ct$是相互正交的（指它们在一个码元周期$T_s$内，其内积运算为0），故我们把$S_I(t)$称为同相分量，而把$S_Q(t)$称为正交分量。而之所以将信号费时费力地分解为同相分量、正交分量，则有抑制镜像干扰、降低接收机误码率等显著功效。

于是，所谓的I/Q信号，是指把信号分别调制在$\cos\omega _ct$与$\sin\omega _ct$这两路相位相差$\pi/2$的同频基带载波上，由于$\cos\omega _ct$与$\sin\omega _ct$是正交的，所以我们才把$S_I(t)$与$S_Q(t)$分别称为同相分量和正交分量，这跟$S_I(t)$与$S_Q(t)$本身是否正交并无关系。更多时候，我们直接把$S_I(t)\cos\omega _ct$称为同相分量，而把$S_Q(t)\sin\omega _ct$称为正交分量。GSM系统中I/Q信号如此，CDMA系统中的I/Q信号亦如此，只是基带载频$\omega_c$有所区别而已。

很显然，如果I/O信号在传输过程中出现干扰、畸变，就会造成信号传输错误。不仅如此，由于$S_I(t)$与$S_Q(t)$要么本身就是模拟信号（由数字码元经脉冲成形滤波器得到，如QPSK调制），要么$S_I(t)$与$S_Q(t)$被调制在$\cos\omega _st$与$\sin\omega _st$上（$\omega_s$，不一定等于$\omega_c$，如MSK调制），它们已经不再是数字信号，而是模拟信号了。所以，I/Q信号线的隔离保护是手机硬件工程师必须着重关注的地方。

#### 2.5.3 Clock 信号

时钟信号皆由振荡电路产生，所以我们有时候也把时钟信号称为振荡信号。时钟信号在手机电路中有着极其重要的作用，无论调制/解调、发射/接收，还是操作系统定时、轮转，亦或是数据传输，都离不开时钟电路。至于时钟电路的具体组成形式与分析方法，笔者在入门篇中就不再介绍了，感兴趣的读者可以直接参阅提高篇中的“时钟系统”，或者电子线路方面的教材。

在此，我们仅仅介绍一下手机中最基本、最核心的两类时钟电路：VC-TCXO与RTC。

**1. VC-TCXO**

VC-TCXO，即温度补偿压控晶体振荡器，在高通平台中常为19.2MHz，其他平台常为13.MH或者26MH2。我们知道，在手机中，RF电路需要本振作为混频器的输入信号源之一（另一个是接收信号），并且本振的频率能够跟随输入信号频率（信道）的变化而变化。所以，这对本振信号的频率稳定度有很高要求。除此以外，诸如DDR SDRAM，MIPI、USB等高速信号线，数据传输率高达几百MHz，对时序要求很严格，否则就会出现传输错误。那么，只有当这些接口芯片的主频保持稳定时（主频可以设置，但通常要求在所设定的频点上保持稳定），才能确保时序合格。

于是，为了使高频本振的频率保持相当的稳定度，人们设计出了PLL（Phase Lock Loop，锁相环）电路，其中一个重要的组件就是具有极高频率稳定度的参考时钟，通常就选用VC-TCXO的输出信号作为该参考时钟。在手机电路中，VC-TCXO总是被封装成一个集成组件，多呈扁平状长方形，其内部主要由变容二极管（Varactor Diode）、石英晶体（Crystal）与放大器（Amplifier）等三大部分组成，实物图与等效电原理图如图2-5-3和图2-5-4所示。

![Jy2j76.png](https://s1.ax1x.com/2020/04/25/Jy2j76.png)

通过控制变容二极管的反向偏置电压AFC（CPU送出的补偿电压），可以改变变容二极管的容值，等效于改变石英晶体的负载电容，从而微调VC-TCXO振荡频率或者保持其振荡频率不随温度变化（故才有温度补偿之说）。

然后，系统以VC-TCXO的输出频率f。为参考时钟，再通过PLL电路合成所需要的各种频率。

**2. RTC**

RTC，全称为Real Time Clock，即实时时钟，常为32.768kHz，主要用于计时、待机守候、系统开机自检等功能。我们在本章2.3.1节中说过，为了有效降低功耗，系统会按照某些规则，关闭部分暂时不需要的电源或者以一定占空比交替打开/关闭部分电源。比如手机在待机状态下，VC-TCXO的供电电源就是时有时无的（请参考图2-3-1）。

但是，RTC是永远不会关闭的，即便在手机关机状态下，RTC也一直工作的。试想，如果RTC关闭了，我们晚上把手机关机，第二天早上再开机，那手机时钟岂不停摆？手机闹铃还如何唤醒？所以，RTC的供电电源永不关闭，只要手机电池有电，RTC就一直工作。

有时候，我们可能会把电池从手机中取出来充电，RTC就会从备份电池（外观与手表中的纽扣电池极为类似，只是尺寸更小）中获得电源，以维持其继续工作。一般，一颗状态良好的备份电池可以为RTC提供不少于45min的供电能力。需要说明的是，有些低端机器从降成本的角度考虑，会把备份电池用一颗大电容代替，其供电能力直接取决于电容容值的大小，通常也就在半分钟到两分钟之间，显然不及备份电池。

就等效电原理图而言，RTC与VC-TCXO并无二致，只不过RTC不需要实时调节振荡频率，所以只要把图2-5-4中的变容二极管用一个普通的电容替代就可以了。但要注意一点，这两个电容的作用一方面是使放大电路形成正反馈（振荡），另一方面是与晶体形成谐振（选频）。所以，为了使RTC时钟更加精确，必须选择满足晶体规格书要求的电容。如果所选电容容值有稍许偏差，问题不是太大，仅仅振荡频率有轻微偏差；但若容值偏差过大，就会导致无法起振或者电压下降后振荡停止的故障。这也就是我们如果用示波器直接测量某些振荡电路的石英晶体管脚时，会导致振荡停止的原因所在。高通QSC6085的RTC就有此问题，如果非要进行测量，则应该测量振荡电路的缓冲器输出管脚。一般而言，振荡频率越高，对电容选择要越加仔细。

最后说明一点，无论VC-TCXO还是RTC，振荡电路的输出信号都是正弦波。如果需要方波振荡信号的话，则只要把正弦波信号送入一个缓冲器（缓冲器其实就是一个工作于开环状态下的运放）中，就可以得到同频方波信号了。进一步地，如果把缓冲器设计成迟滞比较器（又称“施密特触发器”），还可以调整方波信号的占空比。

### 2.6 天线

略

